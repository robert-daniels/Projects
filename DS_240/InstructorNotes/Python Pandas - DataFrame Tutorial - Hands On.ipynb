{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Pandas - DataFrame Tutorial - Hands On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Pandas?\n",
    "\n",
    "- Term Pandas derived from term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for same individuals. \n",
    "\n",
    "- Pandas is a high-level data manipulation tool built on Numpy package and its key data structure is called DataFrame. \n",
    "\n",
    "- Data in pandas is used for statistical analysis in SciPy, plotting functions in Matplotlib, and machine learning algorithms in Scikit-learn. \n",
    "\n",
    "- DataFrames allow us to store and manipulate tabular data in rows of observations and columns of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core components of pandas: Series and DataFrames\n",
    "\n",
    "- Primary two components of pandas are Series and DataFrame.\n",
    "- A Series is a column, and a DataFrame is a multi-dimensional table made up of a collection of Series.\n",
    "- DataFrames and Series are similar, many operations that can be done in one can be done with the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***=============================================================================================================***\n",
    "<br>\n",
    "*** PART - 1 ***\n",
    "<br>\n",
    "***=============================================================================================================***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames - Using Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from CSV files to create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step is to import Pandas libraryâ€¦\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('purchases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display values in data frame\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSVs don't have indexes like DataFrames.\n",
    "- Hence, we can designate index_col when reading file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('purchases.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display values in data frame\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most important DataFrame operations\n",
    "\n",
    "- DataFrames support many methods and operations that are crucial to any analysis. \n",
    "- Let's load IMDB movies dataset from a CSV and designate movie titles to our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"moviedata.csv\", index_col=\"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Movie data\n",
    "\n",
    "- First thing to do when opening new dataset is print out few rows to preview data. \n",
    "- We do this with `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.head()` outputs **first** five rows of DataFrame by default.\n",
    "- But we could also pass a number as well: `movies_df.head(3)` to view top three rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To preview **last** five rows use `.tail()`. \n",
    "- `tail()` also accepts a number, and we preview bottom two rows.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting info about your data\n",
    "\n",
    "- `.info()` provides essential details about our dataset, such as number of rows and columns.\n",
    "- number of non-null values, what type of data is in each column, and how much memory our DataFrame is using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another useful command is `.shape`, which outputs a tuple of (rows, columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that `.shape` has no parentheses and is a simple tuple of format (rows, columns). \n",
    "- So we have **1000 rows** and **11 columns** in our movies DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our dataset does not have duplicate rows, but it is important to verify it anytime we load dataset. \n",
    "\n",
    "To demonstrate, let's simply just double up our movies DataFrame by appending it to itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df = movies_df.append(movies_df)\n",
    "\n",
    "dup_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using `append()` will return a copy without affecting original DataFrame. \n",
    "- We are capturing this copy in `dup_df` without impacting our original 'movies_df' data.\n",
    "\n",
    "**Now we can try dropping duplicates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df = dup_df.drop_duplicates()\n",
    "\n",
    "dup_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we want to work on a dataset and assign result to same dataset as above, there is a better way of doing it.\n",
    "- Pandas has `inplace` keyword argument on many of its methods. \n",
    "- Using `inplace=True` will modify DataFrame object in place as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important argument for `drop_duplicates()` is `keep`, which has three possible options:\n",
    "\n",
    "* `first`: (default) Drop duplicates except for first occurrence.\n",
    "* `last`: Drop duplicates except for last occurrence.\n",
    "* `False`: Drop all duplicates.\n",
    "\n",
    "- If not defined, it defaults to `first`. \n",
    "- `False`,will drop all duplicates. \n",
    "- If two rows are the same then both will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what happens to `dup_df`, when we use 'False':\n",
    "\n",
    "dup_df = movies_df.append(movies_df)  # make a new copy\n",
    "\n",
    "dup_df.drop_duplicates(inplace=True, keep=False)\n",
    "\n",
    "dup_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all rows were duplicates, `keep=False` dropped them all resulting in zero rows being left over. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names cleanup\n",
    "\n",
    "- Sometimes, we may not have the desired column names in our datasets. \n",
    "- It is possible to overwrite the column names, if needed.\n",
    "\n",
    "Here's how to print the column names of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.rename()` method to rename certain or all columns via a `dict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.rename(columns={\n",
    "        'Runtime (Minutes)': 'Runtime', \n",
    "        'Revenue (Millions)': 'Revenue_millions'\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What if we want to lowercase all names? \n",
    "- Instead of using `.rename()` we could assign a list of names to columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns = ['rank', 'genre', 'description', 'director', 'actors', 'year', 'runtime', \n",
    "                     'rating', 'votes', 'revenue_millions', 'metascore']\n",
    "\n",
    "\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting to lower case, one at a time is too much work. \n",
    "- Instead of just renaming each column manually we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns = [col.lower() for col in movies_df]\n",
    "\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to work with missing values\n",
    "\n",
    "- Most commonly we will see Python's `None` or NumPy's `np.nan`.<br>  \n",
    "\n",
    "**There are two options in dealing with nulls:**<br> \n",
    "\n",
    "- Get rid of rows or columns with nulls\n",
    "- Replace nulls with non-null values, a technique known as **imputation**<br><br>\n",
    "\n",
    "- Let's calculate total number of nulls in each column of our dataset. \n",
    "- First step is to check which cells in our DataFrame are null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `isnull()` returns DataFrame where each cell is either True or False depending on that cell's null status.\n",
    "\n",
    "- To count the number of nulls in each column we use an aggregate function for summing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.isnull()` just by iteself isn't very useful, and is usually used in conjunction with other methods, like `sum()`.\n",
    "\n",
    "We can see now that our data has **128** missing values for `revenue_millions` and **64** missing values for `metascore`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing rows with null values\n",
    "\n",
    "Overall, removing null data is only suggested if we have a small amount of missing data.\n",
    "\n",
    "Removing rows with nulls is pretty simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also drop columns with null values by setting `axis=1`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***=============================================================================================================***\n",
    "<br>\n",
    "*** PART - 2 ***\n",
    "<br>\n",
    "***=============================================================================================================***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Missing Values\n",
    "\n",
    "- There may be times where dropping every row with null value removes too much from our dataset.\n",
    "- So instead we can replace null with another value, mostly **mean** or **median** of that column.<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values in revenue_millions column. \n",
    "revenue = movies_df['revenue_millions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use square brackets to select columns in a DataFrame. \n",
    "\n",
    "`revenue` now contains a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different formatting than a DataFrame, but still has `Title` index. \n",
    "\n",
    "- We can replace missing values of revenue using mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating mean value for revenue:\n",
    "revenue_mean = revenue.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill nulls with Revenue Mean using `fillna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue.fillna(revenue_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have replaced all nulls in `revenue` with mean of the column. \n",
    "- By using `inplace=True` we have updated the original `movies_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding dataset variables\n",
    "\n",
    "Using `describe()` on entire DataFrame, we can get summary of distribution of continuous variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['actors'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genre column has 207 unique values, top value is Action/Adventure/Sci-Fi, which shows up 50 times (freq).\n",
    "\n",
    "`.value_counts()` can tell frequency of all values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['actors'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships between continuous variables\n",
    "\n",
    "We can use correlation method `.corr()` to generate relationship between each continuous variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Positive numbers indicate a positive correlation â€” If one goes up other also goes up.<br> \n",
    "- Negative numbers represent an inverse correlation â€” If one goes up other goes down.<br> \n",
    "- 1.0 indicates a perfect correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame slicing, selecting, extracting\n",
    "\n",
    "Below are methods for slicing, selecting, and extracting data.\n",
    "\n",
    "#### By column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_col = movies_df['actors']\n",
    "\n",
    "type(actors_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a *Series*. To extract a column as a *DataFrame*, we need to pass a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_col = movies_df[['actors']]\n",
    "\n",
    "type(actors_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's just a list, adding another column name is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = movies_df[['actors', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at getting data by rows.\n",
    "\n",
    "#### By rows\n",
    "\n",
    "For rows, we have two options: \n",
    "\n",
    "- `.loc` - **loc**ates by name\n",
    "- `.iloc`- **loc**ates by numerical **i**ndex\n",
    "\n",
    "Dataset is indexed by movie Title, so to use `.loc` we give it Title of a movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = movies_df.loc[\"Suicide Squad\"]\n",
    "\n",
    "prom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` will give numerical index of Suicide Squad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = movies_df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` and `iloc` are similar to Python `list` slicing. Let's select multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset = movies_df.loc['Prometheus':'Sing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset = movies_df.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important difference between using `.loc` and `.iloc` to select multiple rows is that `.loc` includes movie *Sing* in result, but when using `.iloc` we're getting rows 1:4 but movie at index 4 (*Suicide Squad*) is not included. \n",
    "\n",
    "Slicing with `.iloc` follows same rules as slicing with lists, object at index at end is not included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data\n",
    "Filter movies DataFrame to show only films directed by Ridley Scott."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['director'] == \"Ridley Scott\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is conditional selections using numerical values by filtering DataFrame by ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['rating'] >= 7.5].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logical operators `|` for \"or\" and `&` for \"and\".\n",
    "\n",
    "Filter DataFrame to show only movies by Christopher Nolan OR Ridley Scott:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[(movies_df['director'] == 'James Gunn') | (movies_df['director'] == 'David Yates')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use group evaluations with parentheses for Python to evaluate the conditional.\n",
    "\n",
    "Using `isin()` method is concise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['director'].isin(['David Yates', 'James Gunn'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All movies released between 2003 and 2010, have rating above 7.5, but made below 100 million in revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\n",
    "    ((movies_df['year'] >= 2003) & (movies_df['year'] <= 2010))\n",
    "    & (movies_df['rating'] > 7.5)\n",
    "    & (movies_df['revenue_millions'] < 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions\n",
    "\n",
    "It is possible to iterate over a DataFrame or Series as you would with a list, but doing so â€” especially on large datasets â€” is very slow.\n",
    "\n",
    "An efficient alternative is to `apply()` a function to the dataset. For example, we could use a function to convert movies with an 8.0 or greater to a string value of \"good\" and the rest to \"bad\" and use this transformed values to create a new column.\n",
    "\n",
    "First we would create a function that, when given a rating, determines if it's good or bad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_function(x):\n",
    "    if x >= 8.0:\n",
    "        return \"good\"\n",
    "    else:\n",
    "        return \"bad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to send the entire rating column through this function, which is what `apply()` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"rating_category\"] = movies_df[\"rating\"].apply(rating_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.apply()` method passes every value in the `rating` column through the `rating_function` and then returns a new Series. This Series is then assigned to a new column called `rating_category`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, using `apply()` will be much faster than iterating manually over rows because pandas is utilizing vectorization.\n",
    "\n",
    "> Vectorization: Batch operations are applied to whole arrays instead of individual elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Plotting\n",
    "\n",
    "Another great thing about pandas is that it integrates with Matplotlib, so you get the ability to plot directly off DataFrames and Series.<br>To get started we need to import Matplotlib (`pip install matplotlib`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set font and plot size to be larger\n",
    "plt.rcParams.update({'font.size': 20, 'figure.figsize': (10, 8)}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**<br>\n",
    "For categorical variables utilize Bar Charts* and Boxplots.<br>\n",
    "For continuous variables utilize Histograms, Scatterplots, Line graphs, and Boxplots.<br>\n",
    "\n",
    "Let's plot the relationship between ratings and revenue.<br> \n",
    "All we need to do is call `.plot()` on `movies_df` with some info about how to construct the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.plot(kind='scatter', x='rating', y='revenue_millions', title='Revenue (millions) vs Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's with the semicolon? It's not a syntax error, just a way to hide the `<matplotlib.axes._subplots.AxesSubplot at 0x26613b5cc18>` output when plotting in Jupyter notebooks.\n",
    "\n",
    "If we want to plot a simple Histogram based on a single column, we can call plot on a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['rating'].plot(kind='hist', title='Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember the `.describe()` example at the beginning of this tutorial? Well, there's a graphical representation of the interquartile range, called the Boxplot. Let's recall what `describe()` gives us on the ratings column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
